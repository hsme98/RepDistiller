{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "39bf04b9-1918-4752-8e1e-e1c098f695cc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-27 16:56:10.624373: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-02-27 16:56:10.626372: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-02-27 16:56:10.666901: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-02-27 16:56:10.667749: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-02-27 16:56:11.938524: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import os\n",
    "import argparse\n",
    "import socket\n",
    "import time\n",
    "\n",
    "import tensorboard_logger as tb_logger\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.backends.cudnn as cudnn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b94386e4-925a-4cb4-b6ac-89be58343bcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here\n"
     ]
    }
   ],
   "source": [
    "print(\"here\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a9ca2dd2-ec0e-4fcb-a042-fd3b6341920f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3a0c3b52-b471-4cc9-9e71-32137ae7890e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0,os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ce585426-1434-4931-abe3-bbfb0d5e41d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import model_dict\n",
    "\n",
    "from dataset.cifar100 import get_cifar100_dataloaders\n",
    "from helper.util import adjust_learning_rate, accuracy, AverageMeter\n",
    "from helper.loops import train_vanilla as train, validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b6fb9eb6-50b5-489a-94c4-7ce3a6f62a84",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_option():\n",
    "\n",
    "    hostname = socket.gethostname()\n",
    "\n",
    "    parser = argparse.ArgumentParser('argument for training')\n",
    "\n",
    "    parser.add_argument('--print_freq', type=int, default=100, help='print frequency')\n",
    "    parser.add_argument('--tb_freq', type=int, default=500, help='tb frequency')\n",
    "    parser.add_argument('--save_freq', type=int, default=40, help='save frequency')\n",
    "    parser.add_argument('--batch_size', type=int, default=64, help='batch_size')\n",
    "    parser.add_argument('--num_workers', type=int, default=8, help='num of workers to use')\n",
    "    parser.add_argument('--epochs', type=int, default=240, help='number of training epochs')\n",
    "\n",
    "    # optimization\n",
    "    parser.add_argument('--learning_rate', type=float, default=0.05, help='learning rate')\n",
    "    parser.add_argument('--lr_decay_epochs', type=str, default='150,180,210', help='where to decay lr, can be a list')\n",
    "    parser.add_argument('--lr_decay_rate', type=float, default=0.1, help='decay rate for learning rate')\n",
    "    parser.add_argument('--weight_decay', type=float, default=5e-4, help='weight decay')\n",
    "    parser.add_argument('--momentum', type=float, default=0.9, help='momentum')\n",
    "\n",
    "    # dataset\n",
    "    parser.add_argument('--model', type=str, default='resnet110',\n",
    "                        choices=['resnet8', 'resnet14', 'resnet20', 'resnet32', 'resnet44', 'resnet56', 'resnet110',\n",
    "                                 'resnet8x4', 'resnet32x4', 'wrn_16_1', 'wrn_16_2', 'wrn_40_1', 'wrn_40_2',\n",
    "                                 'vgg8', 'vgg11', 'vgg13', 'vgg16', 'vgg19',\n",
    "                                 'MobileNetV2', 'ShuffleV1', 'ShuffleV2', ])\n",
    "    parser.add_argument('--dataset', type=str, default='cifar100', choices=['cifar100'], help='dataset')\n",
    "\n",
    "    parser.add_argument('-t', '--trial', type=int, default=0, help='the experiment id')\n",
    "\n",
    "    opt = parser.parse_args(\"\")\n",
    "    \n",
    "    # set different learning rate from these 4 models\n",
    "    if opt.model in ['MobileNetV2', 'ShuffleV1', 'ShuffleV2']:\n",
    "        opt.learning_rate = 0.01\n",
    "\n",
    "    # set the path according to the environment\n",
    "    if hostname.startswith('visiongpu'):\n",
    "        opt.model_path = '/path/to/my/model'\n",
    "        opt.tb_path = '/path/to/my/tensorboard'\n",
    "    else:\n",
    "        opt.model_path = './save/models'\n",
    "        opt.tb_path = './save/tensorboard'\n",
    "\n",
    "    iterations = opt.lr_decay_epochs.split(',')\n",
    "    opt.lr_decay_epochs = list([])\n",
    "    for it in iterations:\n",
    "        opt.lr_decay_epochs.append(int(it))\n",
    "\n",
    "    opt.model_name = '{}_{}_lr_{}_decay_{}_trial_{}'.format(opt.model, opt.dataset, opt.learning_rate,\n",
    "                                                            opt.weight_decay, opt.trial)\n",
    "\n",
    "    opt.tb_folder = os.path.join(opt.tb_path, opt.model_name)\n",
    "    if not os.path.isdir(opt.tb_folder):\n",
    "        os.makedirs(opt.tb_folder)\n",
    "\n",
    "    opt.save_folder = os.path.join(opt.model_path, opt.model_name)\n",
    "    if not os.path.isdir(opt.save_folder):\n",
    "        os.makedirs(opt.save_folder)\n",
    "\n",
    "    return opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9d4a62a6-5fb4-4ce6-aecc-e4fd0b3e422c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "best_acc = 0\n",
    "\n",
    "opt = parse_option()\n",
    "\n",
    "# dataloader\n",
    "if opt.dataset == 'cifar100':\n",
    "    train_loader, val_loader = get_cifar100_dataloaders(batch_size=opt.batch_size, num_workers=opt.num_workers)\n",
    "    n_cls = 100\n",
    "else:\n",
    "    raise NotImplementedError(opt.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2afd4bfb-28c3-4d71-954b-c0375b8dfb90",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5350adc3-3244-4d0d-bce7-a22f8d64785b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/240 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> training...\n",
      "Epoch: [1][0/782]\tTime 24.188 (24.188)\tData 0.229 (0.229)\tLoss 6.7635 (6.7635)\tAcc@1 1.562 (1.562)\tAcc@5 3.125 (3.125)\n",
      "Epoch: [1][100/782]\tTime 0.036 (0.278)\tData 0.001 (0.003)\tLoss 4.6107 (4.7839)\tAcc@1 1.562 (1.006)\tAcc@5 12.500 (4.796)\n",
      "Epoch: [1][200/782]\tTime 0.036 (0.158)\tData 0.001 (0.002)\tLoss 4.5692 (4.6928)\tAcc@1 3.125 (1.112)\tAcc@5 4.688 (5.061)\n",
      "Epoch: [1][300/782]\tTime 0.036 (0.118)\tData 0.001 (0.002)\tLoss 4.5104 (4.6548)\tAcc@1 4.688 (1.199)\tAcc@5 7.812 (5.580)\n",
      "Epoch: [1][400/782]\tTime 0.036 (0.098)\tData 0.001 (0.001)\tLoss 4.5160 (4.6275)\tAcc@1 3.125 (1.321)\tAcc@5 9.375 (5.938)\n",
      "Epoch: [1][500/782]\tTime 0.036 (0.086)\tData 0.001 (0.001)\tLoss 4.4544 (4.6049)\tAcc@1 3.125 (1.422)\tAcc@5 9.375 (6.443)\n",
      "Epoch: [1][600/782]\tTime 0.036 (0.078)\tData 0.001 (0.001)\tLoss 4.3909 (4.5794)\tAcc@1 6.250 (1.552)\tAcc@5 10.938 (7.248)\n",
      "Epoch: [1][700/782]\tTime 0.036 (0.072)\tData 0.001 (0.001)\tLoss 4.4584 (4.5483)\tAcc@1 0.000 (1.743)\tAcc@5 9.375 (8.165)\n",
      " * Acc@1 1.916 Acc@5 8.856\n",
      "epoch 1, total time 53.64\n",
      "Test: [0/313]\tTime 0.313 (0.313)\tLoss 4.3574 (4.3574)\tAcc@1 6.250 (6.250)\tAcc@5 21.875 (21.875)\n",
      "Test: [100/313]\tTime 0.011 (0.014)\tLoss 4.1707 (4.2855)\tAcc@1 6.250 (3.465)\tAcc@5 18.750 (14.666)\n",
      "Test: [200/313]\tTime 0.011 (0.012)\tLoss 4.0527 (4.2705)\tAcc@1 3.125 (3.529)\tAcc@5 21.875 (15.127)\n",
      "Test: [300/313]\tTime 0.011 (0.012)\tLoss 4.2364 (4.2787)\tAcc@1 3.125 (3.644)\tAcc@5 15.625 (15.386)\n",
      " * Acc@1 3.620 Acc@5 15.360\n",
      "saving the best model!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 1/240 [00:57<3:49:57, 57.73s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> training...\n",
      "Epoch: [2][0/782]\tTime 0.277 (0.277)\tData 0.221 (0.221)\tLoss 4.2402 (4.2402)\tAcc@1 6.250 (6.250)\tAcc@5 14.062 (14.062)\n",
      "Epoch: [2][100/782]\tTime 0.036 (0.038)\tData 0.001 (0.003)\tLoss 4.2497 (4.2788)\tAcc@1 7.812 (4.069)\tAcc@5 20.312 (16.368)\n",
      "Epoch: [2][200/782]\tTime 0.036 (0.037)\tData 0.001 (0.002)\tLoss 4.3598 (4.2564)\tAcc@1 1.562 (4.291)\tAcc@5 9.375 (17.055)\n",
      "Epoch: [2][300/782]\tTime 0.036 (0.037)\tData 0.001 (0.002)\tLoss 4.1653 (4.2258)\tAcc@1 9.375 (4.537)\tAcc@5 21.875 (18.205)\n",
      "Epoch: [2][400/782]\tTime 0.036 (0.037)\tData 0.001 (0.001)\tLoss 3.9589 (4.1872)\tAcc@1 10.938 (5.054)\tAcc@5 25.000 (19.428)\n",
      "Epoch: [2][500/782]\tTime 0.036 (0.037)\tData 0.001 (0.001)\tLoss 3.9653 (4.1575)\tAcc@1 4.688 (5.392)\tAcc@5 23.438 (20.459)\n",
      "Epoch: [2][600/782]\tTime 0.036 (0.036)\tData 0.001 (0.001)\tLoss 4.0065 (4.1242)\tAcc@1 7.812 (5.837)\tAcc@5 21.875 (21.456)\n",
      "Epoch: [2][700/782]\tTime 0.036 (0.036)\tData 0.001 (0.001)\tLoss 3.8420 (4.0962)\tAcc@1 4.688 (6.199)\tAcc@5 26.562 (22.361)\n",
      " * Acc@1 6.530 Acc@5 23.138\n",
      "epoch 2, total time 28.50\n",
      "Test: [0/313]\tTime 0.112 (0.112)\tLoss 3.9270 (3.9270)\tAcc@1 6.250 (6.250)\tAcc@5 21.875 (21.875)\n",
      "Test: [100/313]\tTime 0.011 (0.012)\tLoss 3.7464 (4.0097)\tAcc@1 12.500 (8.540)\tAcc@5 43.750 (28.929)\n",
      "Test: [200/313]\tTime 0.011 (0.011)\tLoss 3.7462 (3.9980)\tAcc@1 12.500 (8.909)\tAcc@5 34.375 (29.664)\n",
      "Test: [300/313]\tTime 0.011 (0.011)\tLoss 4.4030 (4.0258)\tAcc@1 3.125 (8.638)\tAcc@5 9.375 (29.205)\n",
      " * Acc@1 8.640 Acc@5 29.400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  1%|          | 2/240 [01:29<2:49:14, 42.67s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving the best model!\n",
      "==> training...\n",
      "Epoch: [3][0/782]\tTime 0.280 (0.280)\tData 0.228 (0.228)\tLoss 4.0881 (4.0881)\tAcc@1 3.125 (3.125)\tAcc@5 25.000 (25.000)\n",
      "Epoch: [3][100/782]\tTime 0.036 (0.039)\tData 0.001 (0.003)\tLoss 3.8999 (3.8411)\tAcc@1 4.688 (9.545)\tAcc@5 34.375 (30.956)\n",
      "Epoch: [3][200/782]\tTime 0.036 (0.037)\tData 0.001 (0.002)\tLoss 3.7317 (3.8016)\tAcc@1 10.938 (10.199)\tAcc@5 40.625 (31.988)\n",
      "Epoch: [3][300/782]\tTime 0.036 (0.037)\tData 0.001 (0.002)\tLoss 3.9705 (3.7667)\tAcc@1 7.812 (10.777)\tAcc@5 32.812 (33.197)\n",
      "Epoch: [3][400/782]\tTime 0.036 (0.037)\tData 0.001 (0.001)\tLoss 3.5255 (3.7399)\tAcc@1 4.688 (11.183)\tAcc@5 39.062 (33.942)\n",
      "Epoch: [3][500/782]\tTime 0.036 (0.037)\tData 0.001 (0.001)\tLoss 3.3739 (3.7092)\tAcc@1 18.750 (11.886)\tAcc@5 39.062 (34.924)\n",
      "Epoch: [3][600/782]\tTime 0.036 (0.037)\tData 0.001 (0.001)\tLoss 3.5784 (3.6775)\tAcc@1 7.812 (12.284)\tAcc@5 40.625 (35.989)\n",
      "Epoch: [3][700/782]\tTime 0.036 (0.037)\tData 0.001 (0.001)\tLoss 3.5432 (3.6467)\tAcc@1 15.625 (12.730)\tAcc@5 42.188 (37.001)\n",
      " * Acc@1 13.066 Acc@5 37.570\n",
      "epoch 3, total time 28.56\n",
      "Test: [0/313]\tTime 0.112 (0.112)\tLoss 3.3869 (3.3869)\tAcc@1 18.750 (18.750)\tAcc@5 53.125 (53.125)\n",
      "Test: [100/313]\tTime 0.011 (0.012)\tLoss 3.2448 (3.4049)\tAcc@1 18.750 (17.543)\tAcc@5 43.750 (43.812)\n",
      "Test: [200/313]\tTime 0.011 (0.011)\tLoss 2.9380 (3.3854)\tAcc@1 25.000 (18.221)\tAcc@5 59.375 (44.667)\n",
      "Test: [300/313]\tTime 0.011 (0.011)\tLoss 3.6645 (3.3934)\tAcc@1 9.375 (17.660)\tAcc@5 37.500 (44.560)\n",
      " * Acc@1 17.630 Acc@5 44.740\n",
      "saving the best model!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  1%|▏         | 3/240 [02:02<2:29:34, 37.87s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> training...\n",
      "Epoch: [4][0/782]\tTime 0.263 (0.263)\tData 0.222 (0.222)\tLoss 3.4678 (3.4678)\tAcc@1 17.188 (17.188)\tAcc@5 42.188 (42.188)\n",
      "Epoch: [4][100/782]\tTime 0.036 (0.038)\tData 0.001 (0.003)\tLoss 3.1561 (3.3680)\tAcc@1 14.062 (17.450)\tAcc@5 54.688 (45.220)\n",
      "Epoch: [4][200/782]\tTime 0.036 (0.037)\tData 0.001 (0.002)\tLoss 3.4601 (3.3141)\tAcc@1 9.375 (18.276)\tAcc@5 39.062 (46.844)\n",
      "Epoch: [4][300/782]\tTime 0.036 (0.037)\tData 0.001 (0.002)\tLoss 3.0546 (3.2844)\tAcc@1 15.625 (18.999)\tAcc@5 53.125 (47.773)\n",
      "Epoch: [4][400/782]\tTime 0.036 (0.037)\tData 0.001 (0.001)\tLoss 3.0008 (3.2563)\tAcc@1 25.000 (19.685)\tAcc@5 57.812 (48.465)\n",
      "Epoch: [4][500/782]\tTime 0.036 (0.037)\tData 0.001 (0.001)\tLoss 3.0776 (3.2294)\tAcc@1 20.312 (20.029)\tAcc@5 54.688 (49.145)\n",
      "Epoch: [4][600/782]\tTime 0.036 (0.037)\tData 0.001 (0.001)\tLoss 2.6410 (3.1993)\tAcc@1 23.438 (20.523)\tAcc@5 57.812 (50.060)\n",
      "Epoch: [4][700/782]\tTime 0.036 (0.037)\tData 0.001 (0.001)\tLoss 3.0358 (3.1738)\tAcc@1 25.000 (20.941)\tAcc@5 50.000 (50.727)\n",
      " * Acc@1 21.378 Acc@5 51.304\n",
      "epoch 4, total time 28.65\n",
      "Test: [0/313]\tTime 0.123 (0.123)\tLoss 3.1295 (3.1295)\tAcc@1 21.875 (21.875)\tAcc@5 56.250 (56.250)\n",
      "Test: [100/313]\tTime 0.011 (0.012)\tLoss 3.4168 (3.3757)\tAcc@1 18.750 (19.926)\tAcc@5 46.875 (46.132)\n",
      "Test: [200/313]\tTime 0.011 (0.012)\tLoss 2.4495 (3.3372)\tAcc@1 34.375 (20.336)\tAcc@5 68.750 (46.813)\n",
      "Test: [300/313]\tTime 0.011 (0.011)\tLoss 3.4363 (3.3341)\tAcc@1 9.375 (20.287)\tAcc@5 46.875 (46.854)\n",
      " * Acc@1 20.300 Acc@5 46.920\n",
      "saving the best model!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  2%|▏         | 4/240 [02:34<2:20:20, 35.68s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> training...\n",
      "Epoch: [5][0/782]\tTime 0.292 (0.292)\tData 0.252 (0.252)\tLoss 3.1254 (3.1254)\tAcc@1 20.312 (20.312)\tAcc@5 51.562 (51.562)\n",
      "Epoch: [5][100/782]\tTime 0.036 (0.038)\tData 0.001 (0.003)\tLoss 2.5322 (2.8818)\tAcc@1 29.688 (25.758)\tAcc@5 70.312 (58.540)\n",
      "Epoch: [5][200/782]\tTime 0.036 (0.037)\tData 0.001 (0.002)\tLoss 2.9024 (2.8649)\tAcc@1 18.750 (26.516)\tAcc@5 56.250 (58.963)\n",
      "Epoch: [5][300/782]\tTime 0.036 (0.037)\tData 0.001 (0.002)\tLoss 2.7053 (2.8563)\tAcc@1 35.938 (26.827)\tAcc@5 64.062 (58.908)\n",
      "Epoch: [5][400/782]\tTime 0.036 (0.037)\tData 0.001 (0.001)\tLoss 3.0244 (2.8448)\tAcc@1 25.000 (27.182)\tAcc@5 60.938 (59.196)\n",
      "Epoch: [5][500/782]\tTime 0.035 (0.036)\tData 0.001 (0.001)\tLoss 2.7513 (2.8300)\tAcc@1 32.812 (27.511)\tAcc@5 60.938 (59.534)\n",
      "Epoch: [5][600/782]\tTime 0.037 (0.036)\tData 0.001 (0.001)\tLoss 3.0151 (2.8122)\tAcc@1 18.750 (27.875)\tAcc@5 57.812 (59.918)\n",
      "Epoch: [5][700/782]\tTime 0.036 (0.036)\tData 0.001 (0.001)\tLoss 2.7408 (2.7912)\tAcc@1 31.250 (28.268)\tAcc@5 62.500 (60.512)\n",
      " * Acc@1 28.578 Acc@5 60.898\n",
      "epoch 5, total time 28.41\n",
      "Test: [0/313]\tTime 0.111 (0.111)\tLoss 2.4567 (2.4567)\tAcc@1 43.750 (43.750)\tAcc@5 71.875 (71.875)\n",
      "Test: [100/313]\tTime 0.011 (0.012)\tLoss 2.8332 (2.6482)\tAcc@1 28.125 (31.281)\tAcc@5 53.125 (63.614)\n",
      "Test: [200/313]\tTime 0.010 (0.011)\tLoss 2.0038 (2.6388)\tAcc@1 40.625 (31.763)\tAcc@5 78.125 (64.164)\n",
      "Test: [300/313]\tTime 0.011 (0.011)\tLoss 3.1983 (2.6438)\tAcc@1 15.625 (31.956)\tAcc@5 50.000 (64.109)\n",
      " * Acc@1 32.100 Acc@5 64.260\n",
      "saving the best model!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  2%|▏         | 5/240 [03:06<2:14:30, 34.34s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> training...\n",
      "Epoch: [6][0/782]\tTime 0.256 (0.256)\tData 0.216 (0.216)\tLoss 2.8986 (2.8986)\tAcc@1 23.438 (23.438)\tAcc@5 60.938 (60.938)\n",
      "Epoch: [6][100/782]\tTime 0.036 (0.038)\tData 0.001 (0.003)\tLoss 2.8880 (2.6392)\tAcc@1 28.125 (30.569)\tAcc@5 64.062 (64.217)\n",
      "Epoch: [6][200/782]\tTime 0.036 (0.037)\tData 0.001 (0.002)\tLoss 2.5741 (2.5974)\tAcc@1 31.250 (31.716)\tAcc@5 64.062 (65.197)\n",
      "Epoch: [6][300/782]\tTime 0.036 (0.037)\tData 0.001 (0.002)\tLoss 2.6882 (2.5702)\tAcc@1 32.812 (32.641)\tAcc@5 64.062 (65.692)\n",
      "Epoch: [6][400/782]\tTime 0.036 (0.037)\tData 0.001 (0.001)\tLoss 2.5437 (2.5491)\tAcc@1 32.812 (33.070)\tAcc@5 65.625 (65.956)\n",
      "Epoch: [6][500/782]\tTime 0.036 (0.036)\tData 0.001 (0.001)\tLoss 2.5067 (2.5321)\tAcc@1 26.562 (33.442)\tAcc@5 70.312 (66.405)\n",
      "Epoch: [6][600/782]\tTime 0.036 (0.036)\tData 0.001 (0.001)\tLoss 2.8055 (2.5153)\tAcc@1 21.875 (33.738)\tAcc@5 62.500 (66.764)\n",
      "Epoch: [6][700/782]\tTime 0.035 (0.036)\tData 0.001 (0.001)\tLoss 2.1781 (2.5024)\tAcc@1 43.750 (34.081)\tAcc@5 78.125 (67.076)\n",
      " * Acc@1 34.324 Acc@5 67.440\n",
      "epoch 6, total time 28.44\n",
      "Test: [0/313]\tTime 0.113 (0.113)\tLoss 2.4767 (2.4767)\tAcc@1 37.500 (37.500)\tAcc@5 65.625 (65.625)\n",
      "Test: [100/313]\tTime 0.011 (0.012)\tLoss 3.1162 (2.4887)\tAcc@1 18.750 (35.613)\tAcc@5 56.250 (68.626)\n",
      "Test: [200/313]\tTime 0.011 (0.011)\tLoss 1.7745 (2.4750)\tAcc@1 37.500 (35.945)\tAcc@5 90.625 (68.719)\n",
      "Test: [300/313]\tTime 0.011 (0.011)\tLoss 3.0272 (2.4815)\tAcc@1 37.500 (36.088)\tAcc@5 59.375 (69.051)\n",
      " * Acc@1 36.100 Acc@5 69.050\n",
      "saving the best model!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  2%|▎         | 6/240 [03:38<2:10:50, 33.55s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> training...\n",
      "Epoch: [7][0/782]\tTime 0.275 (0.275)\tData 0.231 (0.231)\tLoss 2.8655 (2.8655)\tAcc@1 32.812 (32.812)\tAcc@5 56.250 (56.250)\n",
      "Epoch: [7][100/782]\tTime 0.037 (0.040)\tData 0.001 (0.003)\tLoss 2.5052 (2.3316)\tAcc@1 31.250 (37.624)\tAcc@5 65.625 (71.101)\n",
      "Epoch: [7][200/782]\tTime 0.036 (0.039)\tData 0.001 (0.002)\tLoss 2.4362 (2.3312)\tAcc@1 40.625 (37.694)\tAcc@5 70.312 (71.160)\n",
      "Epoch: [7][300/782]\tTime 0.036 (0.038)\tData 0.001 (0.002)\tLoss 2.5412 (2.3253)\tAcc@1 40.625 (38.040)\tAcc@5 57.812 (71.247)\n",
      "Epoch: [7][400/782]\tTime 0.037 (0.037)\tData 0.001 (0.001)\tLoss 2.3026 (2.3173)\tAcc@1 35.938 (38.451)\tAcc@5 71.875 (71.384)\n",
      "Epoch: [7][500/782]\tTime 0.036 (0.037)\tData 0.001 (0.001)\tLoss 2.0843 (2.3079)\tAcc@1 40.625 (38.433)\tAcc@5 79.688 (71.594)\n",
      "Epoch: [7][600/782]\tTime 0.036 (0.037)\tData 0.001 (0.001)\tLoss 2.3574 (2.2985)\tAcc@1 32.812 (38.618)\tAcc@5 65.625 (71.761)\n",
      "Epoch: [7][700/782]\tTime 0.036 (0.037)\tData 0.001 (0.001)\tLoss 2.0019 (2.2906)\tAcc@1 45.312 (38.764)\tAcc@5 78.125 (71.944)\n",
      " * Acc@1 38.902 Acc@5 72.086\n",
      "epoch 7, total time 28.80\n",
      "Test: [0/313]\tTime 0.131 (0.131)\tLoss 2.6025 (2.6025)\tAcc@1 46.875 (46.875)\tAcc@5 75.000 (75.000)\n",
      "Test: [100/313]\tTime 0.011 (0.012)\tLoss 3.3565 (2.3689)\tAcc@1 28.125 (38.707)\tAcc@5 65.625 (72.030)\n",
      "Test: [200/313]\tTime 0.011 (0.011)\tLoss 1.6645 (2.3591)\tAcc@1 53.125 (39.366)\tAcc@5 84.375 (71.906)\n",
      "Test: [300/313]\tTime 0.011 (0.011)\tLoss 2.6329 (2.3772)\tAcc@1 37.500 (38.922)\tAcc@5 71.875 (71.667)\n",
      " * Acc@1 38.900 Acc@5 71.640\n",
      "saving the best model!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  3%|▎         | 7/240 [04:10<2:08:47, 33.16s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> training...\n",
      "Epoch: [8][0/782]\tTime 0.302 (0.302)\tData 0.250 (0.250)\tLoss 2.0139 (2.0139)\tAcc@1 46.875 (46.875)\tAcc@5 70.312 (70.312)\n",
      "Epoch: [8][100/782]\tTime 0.037 (0.040)\tData 0.001 (0.003)\tLoss 2.1456 (2.1442)\tAcc@1 39.062 (41.383)\tAcc@5 79.688 (75.232)\n",
      "Epoch: [8][200/782]\tTime 0.036 (0.039)\tData 0.001 (0.002)\tLoss 2.4025 (2.1462)\tAcc@1 32.812 (41.853)\tAcc@5 70.312 (74.977)\n",
      "Epoch: [8][300/782]\tTime 0.036 (0.038)\tData 0.001 (0.002)\tLoss 1.9459 (2.1424)\tAcc@1 46.875 (41.886)\tAcc@5 75.000 (75.021)\n",
      "Epoch: [8][400/782]\tTime 0.036 (0.037)\tData 0.001 (0.002)\tLoss 2.1373 (2.1423)\tAcc@1 42.188 (41.778)\tAcc@5 73.438 (75.051)\n",
      "Epoch: [8][500/782]\tTime 0.036 (0.037)\tData 0.001 (0.001)\tLoss 2.4453 (2.1389)\tAcc@1 42.188 (41.879)\tAcc@5 68.750 (75.106)\n",
      "Epoch: [8][600/782]\tTime 0.036 (0.037)\tData 0.001 (0.001)\tLoss 2.0733 (2.1337)\tAcc@1 43.750 (42.084)\tAcc@5 78.125 (75.179)\n",
      "Epoch: [8][700/782]\tTime 0.036 (0.037)\tData 0.001 (0.001)\tLoss 2.3804 (2.1314)\tAcc@1 42.188 (42.194)\tAcc@5 70.312 (75.325)\n",
      " * Acc@1 42.276 Acc@5 75.382\n",
      "epoch 8, total time 28.67\n",
      "Test: [0/313]\tTime 0.112 (0.112)\tLoss 2.7329 (2.7329)\tAcc@1 46.875 (46.875)\tAcc@5 65.625 (65.625)\n",
      "Test: [100/313]\tTime 0.011 (0.012)\tLoss 2.6913 (2.3823)\tAcc@1 31.250 (39.356)\tAcc@5 71.875 (72.277)\n",
      "Test: [200/313]\tTime 0.011 (0.011)\tLoss 2.2663 (2.3905)\tAcc@1 25.000 (39.350)\tAcc@5 81.250 (72.030)\n",
      "Test: [300/313]\tTime 0.011 (0.011)\tLoss 2.3829 (2.3925)\tAcc@1 43.750 (39.275)\tAcc@5 71.875 (71.968)\n",
      " * Acc@1 39.270 Acc@5 71.940\n",
      "saving the best model!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  3%|▎         | 8/240 [04:42<2:07:02, 32.86s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> training...\n",
      "Epoch: [9][0/782]\tTime 0.256 (0.256)\tData 0.216 (0.216)\tLoss 1.9905 (1.9905)\tAcc@1 42.188 (42.188)\tAcc@5 76.562 (76.562)\n",
      "Epoch: [9][100/782]\tTime 0.036 (0.038)\tData 0.001 (0.003)\tLoss 2.0352 (1.9950)\tAcc@1 40.625 (44.787)\tAcc@5 78.125 (77.754)\n",
      "Epoch: [9][200/782]\tTime 0.036 (0.037)\tData 0.001 (0.002)\tLoss 2.1634 (2.0137)\tAcc@1 48.438 (44.660)\tAcc@5 76.562 (77.682)\n",
      "Epoch: [9][300/782]\tTime 0.036 (0.037)\tData 0.001 (0.002)\tLoss 1.9785 (2.0116)\tAcc@1 48.438 (44.804)\tAcc@5 76.562 (77.658)\n",
      "Epoch: [9][400/782]\tTime 0.036 (0.036)\tData 0.001 (0.001)\tLoss 1.9332 (2.0156)\tAcc@1 50.000 (44.759)\tAcc@5 79.688 (77.369)\n",
      "Epoch: [9][500/782]\tTime 0.036 (0.036)\tData 0.001 (0.001)\tLoss 1.9563 (2.0163)\tAcc@1 42.188 (44.829)\tAcc@5 76.562 (77.436)\n",
      "Epoch: [9][600/782]\tTime 0.036 (0.036)\tData 0.001 (0.001)\tLoss 2.2003 (2.0190)\tAcc@1 42.188 (44.738)\tAcc@5 73.438 (77.366)\n",
      "Epoch: [9][700/782]\tTime 0.036 (0.036)\tData 0.001 (0.001)\tLoss 2.0414 (2.0168)\tAcc@1 40.625 (44.836)\tAcc@5 76.562 (77.443)\n",
      " * Acc@1 45.068 Acc@5 77.634\n",
      "epoch 9, total time 28.40\n",
      "Test: [0/313]\tTime 0.112 (0.112)\tLoss 2.5091 (2.5091)\tAcc@1 53.125 (53.125)\tAcc@5 75.000 (75.000)\n",
      "Test: [100/313]\tTime 0.011 (0.012)\tLoss 3.0090 (2.5536)\tAcc@1 31.250 (39.202)\tAcc@5 71.875 (70.297)\n",
      "Test: [200/313]\tTime 0.011 (0.011)\tLoss 2.1724 (2.5179)\tAcc@1 37.500 (39.490)\tAcc@5 81.250 (70.989)\n",
      "Test: [300/313]\tTime 0.011 (0.011)\tLoss 2.9821 (2.5290)\tAcc@1 28.125 (39.327)\tAcc@5 59.375 (71.076)\n",
      " * Acc@1 39.300 Acc@5 71.100\n",
      "saving the best model!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  4%|▍         | 9/240 [05:14<2:05:25, 32.58s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> training...\n",
      "Epoch: [10][0/782]\tTime 0.268 (0.268)\tData 0.227 (0.227)\tLoss 1.7393 (1.7393)\tAcc@1 51.562 (51.562)\tAcc@5 82.812 (82.812)\n",
      "Epoch: [10][100/782]\tTime 0.036 (0.038)\tData 0.001 (0.003)\tLoss 2.4269 (1.9557)\tAcc@1 39.062 (46.194)\tAcc@5 67.188 (78.527)\n",
      "Epoch: [10][200/782]\tTime 0.037 (0.037)\tData 0.001 (0.002)\tLoss 2.0424 (1.9413)\tAcc@1 45.312 (46.541)\tAcc@5 79.688 (79.174)\n",
      "Epoch: [10][300/782]\tTime 0.036 (0.037)\tData 0.001 (0.002)\tLoss 1.6071 (1.9268)\tAcc@1 51.562 (46.724)\tAcc@5 82.812 (79.335)\n",
      "Epoch: [10][400/782]\tTime 0.036 (0.037)\tData 0.001 (0.001)\tLoss 1.6820 (1.9271)\tAcc@1 48.438 (46.926)\tAcc@5 82.812 (79.329)\n",
      "Epoch: [10][500/782]\tTime 0.036 (0.036)\tData 0.001 (0.001)\tLoss 1.6560 (1.9371)\tAcc@1 51.562 (46.644)\tAcc@5 85.938 (79.207)\n",
      "Epoch: [10][600/782]\tTime 0.036 (0.036)\tData 0.001 (0.001)\tLoss 1.7261 (1.9273)\tAcc@1 50.000 (46.701)\tAcc@5 81.250 (79.370)\n",
      "Epoch: [10][700/782]\tTime 0.036 (0.036)\tData 0.001 (0.001)\tLoss 1.9539 (1.9288)\tAcc@1 43.750 (46.748)\tAcc@5 82.812 (79.295)\n",
      " * Acc@1 46.754 Acc@5 79.340\n",
      "epoch 10, total time 28.37\n",
      "Test: [0/313]\tTime 0.115 (0.115)\tLoss 2.5489 (2.5489)\tAcc@1 37.500 (37.500)\tAcc@5 65.625 (65.625)\n",
      "Test: [100/313]\tTime 0.011 (0.012)\tLoss 11.4138 (2.6441)\tAcc@1 34.375 (40.934)\tAcc@5 62.500 (73.917)\n",
      "Test: [200/313]\tTime 0.011 (0.011)\tLoss 3.4527 (2.6029)\tAcc@1 43.750 (41.138)\tAcc@5 75.000 (73.368)\n",
      "Test: [300/313]\tTime 0.011 (0.011)\tLoss 2.8270 (2.6041)\tAcc@1 40.625 (41.310)\tAcc@5 62.500 (73.007)\n",
      " * Acc@1 41.330 Acc@5 72.910\n",
      "saving the best model!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  4%|▍         | 10/240 [05:46<2:04:09, 32.39s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> training...\n",
      "Epoch: [11][0/782]\tTime 0.258 (0.258)\tData 0.219 (0.219)\tLoss 1.7647 (1.7647)\tAcc@1 48.438 (48.438)\tAcc@5 84.375 (84.375)\n",
      "Epoch: [11][100/782]\tTime 0.036 (0.038)\tData 0.001 (0.003)\tLoss 1.1156 (1.8098)\tAcc@1 71.875 (49.907)\tAcc@5 92.188 (81.467)\n",
      "Epoch: [11][200/782]\tTime 0.036 (0.037)\tData 0.001 (0.002)\tLoss 2.1046 (1.8472)\tAcc@1 45.312 (49.153)\tAcc@5 70.312 (80.589)\n",
      "Epoch: [11][300/782]\tTime 0.036 (0.037)\tData 0.001 (0.002)\tLoss 1.7678 (1.8518)\tAcc@1 48.438 (48.765)\tAcc@5 85.938 (80.601)\n",
      "Epoch: [11][400/782]\tTime 0.037 (0.036)\tData 0.001 (0.001)\tLoss 1.8410 (1.8519)\tAcc@1 56.250 (48.886)\tAcc@5 76.562 (80.537)\n",
      "Epoch: [11][500/782]\tTime 0.035 (0.036)\tData 0.001 (0.001)\tLoss 2.0163 (1.8539)\tAcc@1 42.188 (48.752)\tAcc@5 75.000 (80.473)\n",
      "Epoch: [11][600/782]\tTime 0.036 (0.036)\tData 0.001 (0.001)\tLoss 1.8063 (1.8489)\tAcc@1 54.688 (48.859)\tAcc@5 81.250 (80.558)\n",
      "Epoch: [11][700/782]\tTime 0.038 (0.036)\tData 0.001 (0.001)\tLoss 1.9400 (1.8522)\tAcc@1 45.312 (48.772)\tAcc@5 75.000 (80.546)\n",
      " * Acc@1 48.866 Acc@5 80.558\n",
      "epoch 11, total time 28.32\n",
      "Test: [0/313]\tTime 0.115 (0.115)\tLoss 2.4243 (2.4243)\tAcc@1 46.875 (46.875)\tAcc@5 71.875 (71.875)\n",
      "Test: [100/313]\tTime 0.011 (0.012)\tLoss 2.6387 (2.1454)\tAcc@1 37.500 (43.410)\tAcc@5 71.875 (76.269)\n",
      "Test: [200/313]\tTime 0.011 (0.011)\tLoss 1.8262 (2.1526)\tAcc@1 56.250 (43.781)\tAcc@5 75.000 (75.171)\n",
      "Test: [300/313]\tTime 0.011 (0.011)\tLoss 2.2900 (2.1782)\tAcc@1 53.125 (43.501)\tAcc@5 81.250 (75.031)\n",
      " * Acc@1 43.490 Acc@5 75.090\n",
      "saving the best model!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  5%|▍         | 11/240 [06:18<2:03:06, 32.25s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> training...\n",
      "Epoch: [12][0/782]\tTime 0.264 (0.264)\tData 0.224 (0.224)\tLoss 1.6299 (1.6299)\tAcc@1 50.000 (50.000)\tAcc@5 84.375 (84.375)\n",
      "Epoch: [12][100/782]\tTime 0.036 (0.038)\tData 0.001 (0.003)\tLoss 1.7143 (1.7878)\tAcc@1 45.312 (50.263)\tAcc@5 84.375 (81.776)\n",
      "Epoch: [12][200/782]\tTime 0.036 (0.037)\tData 0.001 (0.002)\tLoss 1.4997 (1.7828)\tAcc@1 51.562 (50.381)\tAcc@5 87.500 (81.887)\n",
      "Epoch: [12][300/782]\tTime 0.036 (0.037)\tData 0.001 (0.002)\tLoss 2.0416 (1.8029)\tAcc@1 46.875 (49.875)\tAcc@5 75.000 (81.645)\n",
      "Epoch: [12][400/782]\tTime 0.036 (0.037)\tData 0.001 (0.001)\tLoss 1.7291 (1.7974)\tAcc@1 48.438 (49.914)\tAcc@5 85.938 (81.749)\n",
      "Epoch: [12][500/782]\tTime 0.036 (0.036)\tData 0.001 (0.001)\tLoss 1.7859 (1.7959)\tAcc@1 43.750 (50.190)\tAcc@5 85.938 (81.718)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▍         | 11/240 [06:39<2:18:45, 36.36s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 27\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m==> training...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     26\u001b[0m time1 \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m---> 27\u001b[0m train_acc, train_loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     28\u001b[0m time2 \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mepoch \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m, total time \u001b[39m\u001b[38;5;132;01m{:.2f}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(epoch, time2 \u001b[38;5;241m-\u001b[39m time1))\n",
      "File \u001b[0;32m~/RepDistiller/helper/loops.py:26\u001b[0m, in \u001b[0;36mtrain_vanilla\u001b[0;34m(epoch, train_loader, model, criterion, optimizer, opt)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mfloat()\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available():\n\u001b[0;32m---> 26\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43minput\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcuda\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     27\u001b[0m     target \u001b[38;5;241m=\u001b[39m target\u001b[38;5;241m.\u001b[39mcuda()\n\u001b[1;32m     29\u001b[0m \u001b[38;5;66;03m# ===================forward=====================\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# model\n",
    "model = model_dict[opt.model](num_classes=n_cls)\n",
    "\n",
    "# optimizer\n",
    "optimizer = optim.SGD(model.parameters(),\n",
    "                      lr=opt.learning_rate,\n",
    "                      momentum=opt.momentum,\n",
    "                      weight_decay=opt.weight_decay)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    model = model.cuda()\n",
    "    criterion = criterion.cuda()\n",
    "    cudnn.benchmark = True\n",
    "\n",
    "# tensorboard\n",
    "logger = tb_logger.Logger(logdir=opt.tb_folder, flush_secs=2)\n",
    "\n",
    "# routine\n",
    "for epoch in tqdm(range(1, opt.epochs + 1)):\n",
    "\n",
    "    adjust_learning_rate(epoch, opt, optimizer)\n",
    "    print(\"==> training...\")\n",
    "\n",
    "    time1 = time.time()\n",
    "    train_acc, train_loss = train(epoch, train_loader, model, criterion, optimizer, opt)\n",
    "    time2 = time.time()\n",
    "    print('epoch {}, total time {:.2f}'.format(epoch, time2 - time1))\n",
    "\n",
    "    logger.log_value('train_acc', train_acc, epoch)\n",
    "    logger.log_value('train_loss', train_loss, epoch)\n",
    "\n",
    "    test_acc, test_acc_top5, test_loss = validate(val_loader, model, criterion, opt)\n",
    "\n",
    "    logger.log_value('test_acc', test_acc, epoch)\n",
    "    logger.log_value('test_acc_top5', test_acc_top5, epoch)\n",
    "    logger.log_value('test_loss', test_loss, epoch)\n",
    "\n",
    "    # save the best model\n",
    "    if test_acc > best_acc:\n",
    "        best_acc = test_acc\n",
    "        state = {\n",
    "            'epoch': epoch,\n",
    "            'model': model.state_dict(),\n",
    "            'best_acc': best_acc,\n",
    "            'optimizer': optimizer.state_dict(),\n",
    "        }\n",
    "        save_file = os.path.join(opt.save_folder, '{}_best.pth'.format(opt.model))\n",
    "        print('saving the best model!')\n",
    "        torch.save(state, save_file)\n",
    "\n",
    "    # regular saving\n",
    "    if epoch % opt.save_freq == 0:\n",
    "        print('==> Saving...')\n",
    "        state = {\n",
    "            'epoch': epoch,\n",
    "            'model': model.state_dict(),\n",
    "            'accuracy': test_acc,\n",
    "            'optimizer': optimizer.state_dict(),\n",
    "        }\n",
    "        save_file = os.path.join(opt.save_folder, 'ckpt_epoch_{epoch}.pth'.format(epoch=epoch))\n",
    "        torch.save(state, save_file)\n",
    "\n",
    "# This best accuracy is only for printing purpose.\n",
    "# The results reported in the paper/README is from the last epoch.\n",
    "print('best accuracy:', best_acc)\n",
    "\n",
    "# save model\n",
    "state = {\n",
    "    'opt': opt,\n",
    "    'model': model.state_dict(),\n",
    "    'optimizer': optimizer.state_dict(),\n",
    "}\n",
    "save_file = os.path.join(opt.save_folder, '{}_last.pth'.format(opt.model))\n",
    "torch.save(state, save_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4e50301-020d-4163-ab7d-0bf559e5e512",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "new_environment",
   "language": "python",
   "name": "new_environment"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
